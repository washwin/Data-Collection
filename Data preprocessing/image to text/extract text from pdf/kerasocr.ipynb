{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/ashwin/Desktop/Data-Collection/data preprocessing/image to text/.venv/lib/python3.11/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/ashwin/Desktop/Data-Collection/data preprocessing/image to text/.venv/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdf2image\n",
    "import keras_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    images = pdf2image.convert_from_path(pdf_path)\n",
    "    pipeline = keras_ocr.pipeline.Pipeline()\n",
    "    extracted_text = []\n",
    "    for img in images:\n",
    "        detected_text = pipeline.recognize([img])\n",
    "        text = ' '.join([word[0] for word in detected_text[0]])\n",
    "        extracted_text.append(text)\n",
    "    return extracted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /home/ashwin/.keras-ocr/craft_mlt_25k.h5\n",
      "Downloading /home/ashwin/.keras-ocr/craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From /home/ashwin/Desktop/Data-Collection/data preprocessing/image to text/.venv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: resize_bilinear (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.image.resize(...method=ResizeMethod.BILINEAR...)` instead.\n",
      "Looking for /home/ashwin/.keras-ocr/crnn_kurapan.h5\n",
      "Downloading /home/ashwin/.keras-ocr/crnn_kurapan.h5\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'image' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pdf_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_pdfs/sample1.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m extracted_text \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_num, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(extracted_text, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mextract_text_from_pdf\u001b[0;34m(pdf_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m extracted_text \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[0;32m----> 6\u001b[0m     detected_text \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([word[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m detected_text[\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m      8\u001b[0m     extracted_text\u001b[38;5;241m.\u001b[39mappend(text)\n",
      "File \u001b[0;32m~/Desktop/Data-Collection/data preprocessing/image to text/.venv/lib/python3.11/site-packages/keras_ocr/pipeline.py:42\u001b[0m, in \u001b[0;36mPipeline.recognize\u001b[0;34m(self, images, detection_kwargs, recognition_kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure we have an image array to start with.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(images, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m---> 42\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# This turns images into (image, scale) tuples temporarily\u001b[39;00m\n\u001b[1;32m     44\u001b[0m images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     45\u001b[0m     tools\u001b[38;5;241m.\u001b[39mresize_image(image, max_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale, max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_size)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m     47\u001b[0m ]\n",
      "File \u001b[0;32m~/Desktop/Data-Collection/data preprocessing/image to text/.venv/lib/python3.11/site-packages/keras_ocr/pipeline.py:42\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure we have an image array to start with.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(images, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m---> 42\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[43mtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# This turns images into (image, scale) tuples temporarily\u001b[39;00m\n\u001b[1;32m     44\u001b[0m images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     45\u001b[0m     tools\u001b[38;5;241m.\u001b[39mresize_image(image, max_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale, max_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_size)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m     47\u001b[0m ]\n",
      "File \u001b[0;32m~/Desktop/Data-Collection/data preprocessing/image to text/.venv/lib/python3.11/site-packages/keras_ocr/tools.py:38\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filepath_or_buffer)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filepath_or_buffer), (\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find image at path: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m filepath_or_buffer\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(filepath_or_buffer)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mcvtColor(\u001b[43mimage\u001b[49m, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'image' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_path = 'sample_pdfs/sample1.pdf'\n",
    "\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "for page_num, text in enumerate(extracted_text, start=1):\n",
    "    print(f\"Page {page_num}:\\n{text}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
